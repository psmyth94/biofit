import numpy as np
import pandas as pd
import pytest
from biocore.data_handling import DataHandler
from biocore.utils.import_util import is_biosets_available, is_lightgbm_available
from biofit.eval import evaluate
from biofit.models.lasso.lasso import LassoForClassification
from biofit.models.lightgbm.lightgbm import LightGBMForClassification
from biofit.models.random_forest.random_forest import RandomForestForClassification
from biofit.utils.py_util import set_seed

from tests.utils import create_bioset

SUPPORTED_MODELS = [
    "lightgbm",
    "lasso",
    "random_forest",
    # "svm",
]

FORMATS = [
    "pandas",
    "polars",
    "numpy",
    "arrow",
    "dataset",
    "pandas_shuffle",
    "polars_shuffle",
    "arrow_shuffle",
    "dataset_shuffle",
    "pandas_shuffle",
    "polars_seperate",
    "arrow_seperate",
    "dataset_seperate",
    "pandas_cached",
    "polars_cached",
    "numpy_cached",
    "arrow_cached",
    "dataset_cached",
]

EXPECTED_VALS = {
    "binary_classification": {
        "lightgbm": {
            "expected_preds": [
                [0.9535689791828371, 0.0464310208171629],
                [0.9669298162770052, 0.03307018372299475],
                [0.12790019069249647, 0.8720998093075035],
                [0.03757079636968397, 0.962429203630316],
                [0.1846289135978405, 0.8153710864021595],
                [0.05110607323534777, 0.9488939267646522],
                [0.8978708835102494, 0.1021291164897507],
                [0.11111038569821852, 0.8888896143017815],
                [0.44921187388480155, 0.5507881261151985],
                [0.855423097498373, 0.144576902501627],
                [0.8978708835102494, 0.1021291164897507],
                [0.14105769325058248, 0.8589423067494175],
                [0.08034206860142967, 0.9196579313985703],
                [0.0517397023865368, 0.9482602976134632],
                [0.7298271986950035, 0.27017280130499655],
                [0.9540495562336279, 0.045950443766372154],
                [0.9165930028884138, 0.08340699711158621],
                [0.10931200167088684, 0.8906879983291132],
                [0.9385507945257092, 0.061449205474290745],
                [0.8948719161714075, 0.10512808382859253],
                [0.8973383378571904, 0.10266166214280961],
                [0.11639013253708874, 0.8836098674629113],
                [0.956052390852163, 0.04394760914783706],
                [0.9612289867007701, 0.038771013299229905],
                [0.2755781540774306, 0.7244218459225694],
                [0.947484475608107, 0.05251552439189295],
                [0.9013976735797605, 0.09860232642023944],
                [0.037727020474712436, 0.9622729795252876],
                [0.9753215964143493, 0.02467840358565063],
                [0.7162318325330577, 0.2837681674669423],
                [0.10419336890743847, 0.8958066310925615],
                [0.4044412343918701, 0.5955587656081299],
                [0.9730656228707297, 0.026934377129270236],
                [0.11318279020889954, 0.8868172097911005],
                [0.036295649741235, 0.963704350258765],
                [0.48345509058787506, 0.5165449094121249],
                [0.9670021170214806, 0.03299788297851934],
                [0.05377327588513203, 0.946226724114868],
                [0.07216314186313177, 0.9278368581368682],
                [0.8387195459495832, 0.1612804540504168],
                [0.9685902354188991, 0.03140976458110088],
                [0.10931200167088684, 0.8906879983291132],
                [0.03757079636968397, 0.962429203630316],
                [0.22858955836206873, 0.7714104416379313],
                [0.972921875983505, 0.027078124016494988],
                [0.7921953615847763, 0.20780463841522362],
                [0.9675038597561006, 0.032496140243899345],
                [0.11327252137195587, 0.8867274786280441],
                [0.07512499995791921, 0.9248750000420808],
                [0.035676949760042875, 0.9643230502399571],
                [0.8834766324397875, 0.11652336756021252],
                [0.9660311161320242, 0.033968883867975835],
                [0.5879269539460168, 0.41207304605398315],
                [0.7434865393955636, 0.2565134606044363],
                [0.11382126481839294, 0.8861787351816071],
                [0.17946079428899442, 0.8205392057110056],
                [0.05801699845027686, 0.9419830015497231],
                [0.26289780273304264, 0.7371021972669574],
                [0.8444282511876444, 0.15557174881235555],
            ],
            "expected_metrics": {
                "logloss": 0.16449683853287383,
                "logloss_weighted": 0.16449683853287383,
                "auc": np.float64(0.9956),
                "f1": np.float64(0.98),
                "accuracy": 0.98,
                "balanced_accuracy": np.float64(0.98),
                "precision": np.float64(0.98),
                "recall": np.float64(0.98),
                "specificity": np.float64(0.98),
            },
        },
        "lasso": {
            "expected_preds": [
                [0.7816936873086878, 0.21830631269131215],
                [0.31624928527411866, 0.6837507147258813],
                [0.31175710811128376, 0.6882428918887162],
                [0.3327395758214362, 0.6672604241785638],
                [0.30591660281237865, 0.6940833971876214],
                [0.27231695202635364, 0.7276830479736464],
                [0.7881033635355769, 0.2118966364644231],
                [0.23754846287095566, 0.7624515371290443],
                [0.25642166051074533, 0.7435783394892547],
                [0.32707066935266993, 0.6729293306473301],
                [0.6891296880681221, 0.3108703119318779],
                [0.5981991819110841, 0.40180081808891593],
                [0.25115314289900026, 0.7488468571009997],
                [0.5734621177488353, 0.42653788225116473],
                [0.32864980374690667, 0.6713501962530933],
                [0.6462823930480115, 0.3537176069519885],
                [0.6384700780622443, 0.3615299219377557],
                [0.3350062784077973, 0.6649937215922027],
                [0.48056137630666895, 0.519438623693331],
                [0.5153027484675532, 0.48469725153244675],
                [0.3115503620089727, 0.6884496379910273],
                [0.20750955945016547, 0.7924904405498345],
                [0.4022895107130673, 0.5977104892869327],
                [0.5570701111034967, 0.4429298888965033],
                [0.46231437748106563, 0.5376856225189344],
                [0.5336473794374168, 0.46635262056258314],
                [0.8974911435749764, 0.10250885642502364],
                [0.5698967574554465, 0.4301032425445534],
                [0.8699974284228695, 0.13000257157713047],
                [0.18044140781683704, 0.819558592183163],
                [0.3065589974178936, 0.6934410025821064],
                [0.7661916377320677, 0.23380836226793236],
                [0.46470999173188965, 0.5352900082681104],
                [0.30624315426509185, 0.6937568457349081],
                [0.29512360607920796, 0.704876393920792],
                [0.6455959800560582, 0.35440401994394183],
                [0.6765435056409852, 0.3234564943590148],
                [0.29782956675631833, 0.7021704332436817],
                [0.21753403619181588, 0.7824659638081841],
                [0.7948865980678086, 0.20511340193219144],
                [0.824249495776864, 0.17575050422313598],
                [0.39307615244097227, 0.6069238475590277],
                [0.4115183697470993, 0.5884816302529007],
                [0.5313818223941422, 0.4686181776058578],
                [0.5972677846657815, 0.4027322153342186],
                [0.5477712695165392, 0.4522287304834608],
                [0.74534004641736, 0.25465995358264004],
                [0.35323735627572894, 0.6467626437242711],
                [0.4471767406356947, 0.5528232593643053],
                [0.23015436437358872, 0.7698456356264113],
                [0.6962745670430985, 0.3037254329569014],
                [0.8336952862635421, 0.16630471373645794],
                [0.42658011594906, 0.57341988405094],
                [0.30674813687003766, 0.6932518631299623],
                [0.24919868347662733, 0.7508013165233727],
                [0.36639539420598566, 0.6336046057940143],
                [0.6101778533199422, 0.3898221466800577],
                [0.7757372692814383, 0.22426273071856173],
                [0.5574921398591706, 0.44250786014082943],
            ],
            "expected_metrics": {
                "logloss": 0.5865464808741376,
                "logloss_weighted": 0.5865464808741376,
                "auc": np.float64(0.7508),
                "f1": np.float64(0.6990291262135923),
                "accuracy": 0.69,
                "balanced_accuracy": np.float64(0.69),
                "precision": np.float64(0.6792452830188679),
                "recall": np.float64(0.72),
                "specificity": np.float64(0.66),
            },
        },
        "random_forest": {
            "expected_preds": [
                [0.98, 0.02],
                [0.95, 0.05],
                [0.16, 0.84],
                [0.03, 0.97],
                [0.08, 0.92],
                [0.0, 1.0],
                [0.97, 0.03],
                [0.02, 0.98],
                [0.68, 0.32],
                [0.8, 0.2],
                [0.84, 0.16],
                [0.11, 0.89],
                [0.16, 0.84],
                [0.06, 0.94],
                [0.75, 0.25],
                [0.89, 0.11],
                [0.87, 0.13],
                [0.08, 0.92],
                [0.79, 0.21],
                [0.91, 0.09],
                [0.75, 0.25],
                [0.07, 0.93],
                [0.96, 0.04],
                [0.96, 0.04],
                [0.19, 0.81],
                [0.91, 0.09],
                [0.98, 0.02],
                [0.05, 0.95],
                [0.99, 0.01],
                [0.64, 0.36],
                [0.2, 0.8],
                [0.28, 0.72],
                [0.9, 0.1],
                [0.17, 0.83],
                [0.0, 1.0],
                [0.35, 0.65],
                [0.95, 0.05],
                [0.01, 0.99],
                [0.11, 0.89],
                [0.86, 0.14],
                [0.95, 0.05],
                [0.05, 0.95],
                [0.04, 0.96],
                [0.23, 0.77],
                [0.93, 0.07],
                [0.82, 0.18],
                [0.91, 0.09],
                [0.18, 0.82],
                [0.11, 0.89],
                [0.01, 0.99],
                [0.96, 0.04],
                [0.99, 0.01],
                [0.83, 0.17],
                [0.6, 0.4],
                [0.06, 0.94],
                [0.3, 0.7],
                [0.06, 0.94],
                [0.3, 0.7],
                [0.87, 0.13],
            ],
            "expected_metrics": {
                "logloss": 0.13027149699327187,
                "logloss_weighted": 0.13027149699327187,
                "auc": np.float64(1.0),
                "f1": np.float64(1.0),
                "accuracy": 1.0,
                "balanced_accuracy": np.float64(1.0),
                "precision": np.float64(1.0),
                "recall": np.float64(1.0),
                "specificity": np.float64(1.0),
            },
        },
    },
    "multi_class_classification": {
        "lightgbm": {
            "expected_preds": [
                [0.593146054103032, 0.3544863375913485, 0.05236760830561952],
                [0.0162947366442909, 0.08966806138760489, 0.8940372019681042],
                [0.7314477097580847, 0.08987852215806323, 0.1786737680838522],
                [0.9513440600973485, 0.02558212227442155, 0.02307381762822989],
                [0.08076421066646375, 0.8471446489996138, 0.07209114033392237],
                [0.024941657594269584, 0.8349486385255367, 0.14010970388019373],
                [0.8080818936953171, 0.11152838686995886, 0.08038971943472402],
                [0.3745713232222257, 0.1005204106433833, 0.524908266134391],
                [0.03084559346731874, 0.7175825421822467, 0.2515718643504347],
                [0.9264354653778086, 0.040485517926432894, 0.03307901669575851],
                [0.26169193369944177, 0.6432778275261304, 0.09503023877442779],
                [0.05390047046164553, 0.12321047791027544, 0.822889051628079],
                [0.9893123044084093, 0.0033716628402068512, 0.007316032751383729],
                [0.04989245219405661, 0.5164105654452859, 0.43369698236065757],
                [0.8965695794118023, 0.04655120246031727, 0.05687921812788048],
                [0.09683252885215721, 0.8737826902595416, 0.02938478088830118],
                [0.018979028711999975, 0.3854551955203541, 0.595565775767646],
                [0.015064114607673476, 0.06491993148499259, 0.9200159539073338],
                [0.2501257382333796, 0.07557633061268863, 0.6742979311539318],
                [0.01260103830566784, 0.950366380134126, 0.03703258156020627],
                [0.057080075231720706, 0.8878873343593096, 0.05503259040896966],
                [0.14887379039370122, 0.7141974476107982, 0.13692876199550066],
                [0.022279213512249003, 0.9685747767923893, 0.009146009695361583],
                [0.36701992326651967, 0.4247852501339898, 0.20819482659949057],
                [0.9432880138214005, 0.02093608544659706, 0.03577590073200245],
                [0.21445840357507803, 0.12505753739912728, 0.6604840590257947],
                [0.9850150858045772, 0.005457083883926245, 0.009527830311496462],
                [0.008149987927395205, 0.9720361230965696, 0.019813888976035123],
                [0.5787640351932142, 0.3587723056494069, 0.06246365915737892],
                [0.058630546812436284, 0.11549220701190936, 0.8258772461756545],
                [0.9415956567242569, 0.0017096868247902064, 0.056694656450952965],
                [0.8401430809052793, 0.005159964181618216, 0.1546969549131024],
                [0.3373342066378342, 0.05918842349172757, 0.6034773698704382],
                [0.011080447400212695, 0.9116047621274613, 0.07731479047232594],
                [0.3693202163184197, 0.26089826875819366, 0.3697815149233866],
                [0.09434666971449106, 0.2436016225971083, 0.6620517076884006],
                [0.012044889962176637, 0.15740806448518946, 0.8305470455526338],
                [0.9625788280022749, 0.006700416704897087, 0.030720755292827962],
                [0.0314960379961621, 0.018228459472588898, 0.9502755025312489],
                [0.07180604640327914, 0.21617724025134022, 0.7120167133453806],
                [0.9909239929523648, 0.002762349978571398, 0.006313657069063688],
                [0.8467504500331269, 0.014471453132731507, 0.13877809683414177],
                [0.17742037837331487, 0.7239156681031946, 0.0986639535234905],
                [0.963211960496519, 0.006581222131420159, 0.030206817372060775],
                [0.9867858584643275, 0.002130638765929315, 0.01108350276974304],
                [0.011223976533424277, 0.9234131157628203, 0.06536290770375551],
                [0.013413129940471473, 0.9751884803477013, 0.011398389711827031],
                [0.8890369114051427, 0.057398540656221825, 0.053564547938635396],
                [0.7393617652660448, 0.1762448283804414, 0.08439340635351382],
                [0.0026998424032764717, 0.8961457621237923, 0.10115439547293113],
                [0.04922197852764869, 0.9004333884777317, 0.050344632994619644],
                [0.009004793995118152, 0.8620266528963505, 0.12896855310853148],
                [0.004300474674760467, 0.9410398929508006, 0.05465963237443907],
                [0.016551281611928693, 0.07217063275491635, 0.911278085633155],
                [0.22490788573213896, 0.7139179765022333, 0.06117413776562761],
                [0.9519439180445933, 0.010465037470341117, 0.037591044485065436],
                [0.9358052195418675, 0.011508047597263087, 0.05268673286086945],
                [0.07397151864688836, 0.08594553167721526, 0.8400829496758964],
                [0.9486043978269892, 0.019309808345722143, 0.03208579382728866],
            ],
            "expected_metrics": {
                "mlogloss": 0.1996362230208467,
                "mlogloss_weighted": 0.19985753361762523,
                "accuracy": 0.97,
                "balanced_accuracy": np.float64(0.9702911467617351),
                "f1_macro": np.float64(0.969998492386552),
                "f1_micro": np.float64(0.97),
                "f1_weighted": np.float64(0.9699954771596563),
                "precision_macro": np.float64(0.9705882352941178),
                "precision_micro": np.float64(0.97),
                "precision_weighted": np.float64(0.9708823529411765),
                "recall_macro": np.float64(0.9702911467617351),
                "recall_micro": np.float64(0.97),
                "recall_weighted": np.float64(0.97),
                "specificity_macro": np.float64(0.9850746268656717),
                "specificity_weighted": np.float64(0.9852238805970149),
            },
        },
        "lasso": {
            "expected_preds": [
                [0.727717303959388, 0.23690670804022768, 0.03537598800038429],
                [0.18692727398823294, 0.11157108480807601, 0.7015016412036912],
                [0.34309525593719364, 0.1765917153709202, 0.48031302869188613],
                [0.5538856681121752, 0.16189352573200325, 0.2842208061558217],
                [0.6211387488472769, 0.14887956386778411, 0.22998168728493895],
                [0.08136652003632926, 0.7405643083523318, 0.178069171611339],
                [0.759360225300843, 0.13038683194736123, 0.11025294275179577],
                [0.7439536052085204, 0.11809572286257745, 0.13795067192890215],
                [0.23857065761662077, 0.41094065879844277, 0.35048868358493646],
                [0.7701695624738958, 0.16052746174977564, 0.06930297577632857],
                [0.2933931613744791, 0.60926996361502, 0.09733687501050099],
                [0.147242819833966, 0.4228473626130698, 0.42990981755296426],
                [0.9621888073691544, 0.0008644135412697095, 0.036946779089575964],
                [0.01705558890825475, 0.11664143509420513, 0.8663029759975402],
                [0.3893194843740159, 0.3280460247431107, 0.28263449088287346],
                [0.39448406752573534, 0.25421966960835124, 0.3512962628659135],
                [0.07706673345013908, 0.792292432198681, 0.13064083435118],
                [0.2569720803873218, 0.022213793505098937, 0.7208141261075793],
                [0.4051741803656034, 0.30944209380006654, 0.2853837258343301],
                [0.03527785507203288, 0.8355004491958612, 0.12922169573210607],
                [0.13010121295474616, 0.5270237025408331, 0.3428750845044207],
                [0.48615577104471547, 0.28824697580116326, 0.22559725315412132],
                [0.06686616038986118, 0.9040761159727345, 0.029057723637404262],
                [0.22016199312436038, 0.18946190384464945, 0.5903761030309902],
                [0.887645228005912, 0.05455414993455491, 0.057800622059533145],
                [0.10492818962033762, 0.23688245995737642, 0.658189350422286],
                [0.6561865190807977, 0.06952320441570069, 0.27429027650350163],
                [0.056170413275787576, 0.7340325149666672, 0.20979707175754517],
                [0.3467095278403483, 0.49654341645234773, 0.156747055707304],
                [0.14269187448939388, 0.29671434149381504, 0.5605937840167912],
                [0.8597096595076208, 0.003057035249782796, 0.13723330524259655],
                [0.5412733542712894, 0.06458744307929185, 0.39413920264941876],
                [0.768266090194226, 0.04860121636266081, 0.1831326934431133],
                [0.2116624126426145, 0.5105721747127452, 0.27776541264464033],
                [0.13321208490679914, 0.6243477238858032, 0.24244019120739774],
                [0.049943991269237, 0.42310719519145185, 0.5269488135393112],
                [0.15853416173853788, 0.3785164681414171, 0.4629493701200449],
                [0.9085156781663416, 0.03340196488561009, 0.05808235694804848],
                [0.16236725942071278, 0.14571741821409478, 0.6919153223651924],
                [0.11524093905630521, 0.20831478654951238, 0.6764442743941824],
                [0.847819055621279, 0.009838453305903732, 0.1423424910728173],
                [0.09772981091930481, 0.012648051184822403, 0.8896221378958727],
                [0.4151595507653043, 0.45189425384898724, 0.1329461953857084],
                [0.8300230582936061, 0.003552826486441063, 0.16642411521995287],
                [0.9509389107752908, 0.0020869188052771133, 0.04697417041943202],
                [0.11616015578071352, 0.7491230372424216, 0.13471680697686486],
                [0.42501082628592196, 0.34458353378516193, 0.230405639928916],
                [0.3747387868476141, 0.4898130370047601, 0.1354481761476259],
                [0.25984451234985434, 0.39972345466155934, 0.3404320329885864],
                [0.0670850052509371, 0.7474444842869399, 0.185470510462123],
                [0.3192185535429023, 0.4248999983362068, 0.25588144812089086],
                [0.08374375640315046, 0.6594847821394243, 0.25677146145742524],
                [0.035162467740786844, 0.8535509674940139, 0.11128656476519908],
                [0.2098548230221486, 0.3014144284213309, 0.4887307485565204],
                [0.027996101265055064, 0.8653440168301139, 0.10665988190483106],
                [0.636044154536507, 0.050639795480214446, 0.31331604998327856],
                [0.744216538349922, 0.08092876869163469, 0.17485469295844333],
                [0.1723251482898169, 0.014796167284032756, 0.8128786844261504],
                [0.8461973185412733, 0.10200854616835917, 0.05179413529036747],
            ],
            "expected_metrics": {
                "mlogloss": 0.7093916124597448,
                "mlogloss_weighted": 0.7094112118294117,
                "accuracy": 0.73,
                "balanced_accuracy": np.float64(0.7302436125965537),
                "f1_macro": np.float64(0.7299465240641712),
                "f1_micro": np.float64(0.73),
                "f1_weighted": np.float64(0.7299197860962567),
                "precision_macro": np.float64(0.7305194805194807),
                "precision_micro": np.float64(0.73),
                "precision_weighted": np.float64(0.7307142857142856),
                "recall_macro": np.float64(0.7302436125965537),
                "recall_micro": np.float64(0.73),
                "recall_weighted": np.float64(0.73),
                "specificity_macro": np.float64(0.8650685964118799),
                "specificity_weighted": np.float64(0.8652057892356401),
            },
        },
        "random_forest": {
            "expected_preds": [
                [0.87, 0.13, 0.0],
                [0.0, 0.06, 0.94],
                [0.75, 0.09, 0.16],
                [0.79, 0.16, 0.05],
                [0.22, 0.77, 0.01],
                [0.07, 0.74, 0.19],
                [0.87, 0.11, 0.02],
                [0.27, 0.01, 0.72],
                [0.02, 0.83, 0.15],
                [0.92, 0.06, 0.02],
                [0.28, 0.64, 0.08],
                [0.09, 0.12, 0.79],
                [0.98, 0.01, 0.01],
                [0.05, 0.7, 0.25],
                [0.69, 0.23, 0.08],
                [0.1, 0.86, 0.04],
                [0.06, 0.24, 0.7],
                [0.07, 0.04, 0.89],
                [0.24, 0.09, 0.67],
                [0.06, 0.93, 0.01],
                [0.15, 0.81, 0.04],
                [0.15, 0.65, 0.2],
                [0.03, 0.94, 0.03],
                [0.24, 0.62, 0.14],
                [0.96, 0.01, 0.03],
                [0.1, 0.04, 0.86],
                [0.94, 0.05, 0.01],
                [0.04, 0.92, 0.04],
                [0.76, 0.18, 0.06],
                [0.01, 0.07, 0.92],
                [0.79, 0.07, 0.14],
                [0.88, 0.05, 0.07],
                [0.27, 0.09, 0.64],
                [0.02, 0.95, 0.03],
                [0.69, 0.15, 0.16],
                [0.01, 0.2, 0.79],
                [0.04, 0.14, 0.82],
                [0.94, 0.03, 0.03],
                [0.03, 0.06, 0.91],
                [0.14, 0.14, 0.72],
                [0.98, 0.01, 0.01],
                [0.79, 0.02, 0.19],
                [0.2, 0.76, 0.04],
                [0.9, 0.03, 0.07],
                [0.99, 0.0, 0.01],
                [0.01, 0.94, 0.05],
                [0.02, 0.89, 0.09],
                [0.83, 0.04, 0.13],
                [0.7, 0.16, 0.14],
                [0.01, 0.91, 0.08],
                [0.06, 0.84, 0.1],
                [0.05, 0.86, 0.09],
                [0.02, 0.83, 0.15],
                [0.0, 0.14, 0.86],
                [0.13, 0.72, 0.15],
                [0.81, 0.06, 0.13],
                [0.85, 0.02, 0.13],
                [0.06, 0.01, 0.93],
                [0.92, 0.04, 0.04],
            ],
            "expected_metrics": {
                "mlogloss": 0.18626589694153936,
                "mlogloss_weighted": 0.1865393454742004,
                "accuracy": 1.0,
                "balanced_accuracy": np.float64(1.0),
                "f1_macro": np.float64(1.0),
                "f1_micro": np.float64(1.0),
                "f1_weighted": np.float64(1.0),
                "precision_macro": np.float64(1.0),
                "precision_micro": np.float64(1.0),
                "precision_weighted": np.float64(1.0),
                "recall_macro": np.float64(1.0),
                "recall_micro": np.float64(1.0),
                "recall_weighted": np.float64(1.0),
                "specificity_macro": np.float64(1.0),
                "specificity_weighted": np.float64(1.0),
            },
        },
    },
}


pytestmark = pytest.mark.integration


@pytest.mark.parametrize("format", FORMATS)
@pytest.mark.parametrize("model_name", SUPPORTED_MODELS)
def test_eval_binary_classification(
    classification_data, sample_metadata, model_name, format
):
    run_test_eval(
        classification_data,
        sample_metadata,
        model_name,
        format,
        "binary_classification",
    )


@pytest.mark.parametrize("format", FORMATS)
@pytest.mark.parametrize("model_name", SUPPORTED_MODELS)
def test_eval_multi_class_classification(
    classification_data_multi_class, sample_metadata, model_name, format
):
    run_test_eval(
        classification_data_multi_class,
        sample_metadata,
        model_name,
        format,
        "multi_class_classification",
    )


def run_test_eval(classification_data, sample_metadata, model_name, format, task):
    format = format.replace("_cached", "")
    X, y = classification_data
    _run_eval(model_name, X, y, sample_metadata, format, task)


def _run_eval(model_name, X, y, sample_metadata, format, task):
    set_seed(42)
    if model_name == "lightgbm":
        if not is_lightgbm_available():
            pytest.skip("test requires lightgbm")
        model = LightGBMForClassification()
    elif model_name == "lasso":
        model = LassoForClassification()
    elif model_name == "random_forest":
        model = RandomForestForClassification()

    otu_dataset = pd.concat([sample_metadata, X, y], axis=1)

    input_columns = list(X.columns)
    target_column = list(y.columns)[0]
    if format == "numpy":
        data = DataHandler.to_numpy(X)
        target = DataHandler.to_numpy(y)
        model.fit(data, target)
        preds, metrics = evaluate(model, data, target)
    elif "seperate" in format:
        new_format = format.replace("_seperate", "")
        data = X
        target = y
        if new_format == "dataset":
            if not is_biosets_available():
                pytest.skip("test requires biosets")
            from biosets.features import Abundance, BinClassLabel

            otu_dataset = create_bioset(
                X=X,
                y=y,
                sample_metadata=sample_metadata,
                with_feature_metadata=True,
                feature_type=Abundance,
                target_type=BinClassLabel,
            )

            model.fit(data, target)
            preds, metrics = evaluate(model, otu_dataset, target)
        else:
            data = DataHandler.to_format(data, new_format)
            target = DataHandler.to_format(target, new_format)
            model.fit(data, target)
            preds, metrics = evaluate(model, data, target)
    elif "shuffle" in format:
        # here we test to see if output is the same when columns are shuffled
        new_format = format.replace("_shuffle", "")
        columns = DataHandler.get_column_names(otu_dataset)
        np.random.seed(42)
        columns = np.random.permutation(columns).tolist()
        if new_format == "dataset":
            if not is_biosets_available():
                pytest.skip("test requires biosets")
            from biosets.features import Abundance, BinClassLabel

            otu_dataset = create_bioset(
                X=X,
                y=y,
                sample_metadata=sample_metadata,
                with_feature_metadata=True,
                feature_type=Abundance,
                target_type=BinClassLabel,
            )

            data = otu_dataset
            model.fit(data)
            data = DataHandler.select_columns(data, columns)
            preds, metrics = evaluate(
                model,
                data,
            )
        else:
            data = DataHandler.to_format(otu_dataset, new_format)
            model.fit(
                data,
                target_column=target_column,
                input_columns=input_columns,
            )
            data = DataHandler.select_columns(data, columns)
            columns = [col for col in columns if col in input_columns]
            # add extra random columns
            data_dim = DataHandler.get_shape(data)
            for i in range(5):
                data = DataHandler.append_column(
                    data, f"extra_col_{i}", np.array([0] * data_dim[0], dtype=np.int32)
                )
            columns += [f"extra_col_{i}" for i in range(5)]
            preds, metrics = evaluate(
                model,
                data,
                target_columns=target_column,
                input_columns=input_columns,
            )
    else:
        if format == "dataset":
            if not is_biosets_available():
                pytest.skip("test requires biosets")
            from biosets.features import Abundance, BinClassLabel

            otu_dataset = create_bioset(
                X=X,
                y=y,
                sample_metadata=sample_metadata,
                with_feature_metadata=True,
                feature_type=Abundance,
                target_type=BinClassLabel,
            )

            data = otu_dataset
            model.fit(data)
            preds, metrics = evaluate(
                model,
                data,
            )
        else:
            data = DataHandler.to_format(otu_dataset, format)
            model.fit(
                data,
                target_column=target_column,
                input_columns=input_columns,
            )
            preds, metrics = evaluate(
                model,
                data,
                target_columns=target_column,
                input_columns=input_columns,
            )

    ev = EXPECTED_VALS[task][model_name]
    for i, pred in enumerate(preds.values.tolist()[:59]):
        val = ev["expected_preds"][i]
        assert pred == pytest.approx(
            val, abs=0.1
        ), f"Prediction {pred} does not match the expected value {val}."

    for metric, expected_value in ev["expected_metrics"].items():
        assert metrics[metric] == pytest.approx(
            expected_value, abs=1e-2
        ), f"Metric {metric} does not match the expected value."
